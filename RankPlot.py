import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import ElasticNetCV
from xgboost import XGBRegressor
import matplotlib.pyplot as plt
import os

# ==========================
# å‚æ•°è®¾ç½®ï¼ˆå’ŒåŸè„šæœ¬ä¿æŒä¸€è‡´ï¼‰
# ==========================

TOP_K = 30

# è¿™é‡Œåªç”»â€œè‡ªè¯„â€ç„¦è™‘ / æŠ‘éƒï¼Œå¯¹åº”ä½ é˜¶æ®µäºŒä½¿ç”¨çš„ä¸¤ä¸ªæ ‡ç­¾
TARGETS_FOR_PLOT = [
    "a_promis_anx_bline",
    "a_promis_dep_bline",
]

# å¦‚æœä½ ä¹‹åæƒ³å¯¹æ‰€æœ‰å››ä¸ª target éƒ½ç”»å›¾ï¼Œå¯ä»¥æŠŠä¸Šé¢åˆ—è¡¨æ”¹æˆåŸæ¥é‚£å››ä¸ª

file_path = r"C:\Users\Lenovo\Desktop\MATH 4890\å˜é‡ç­›é€‰_cleaned.xlsx"
output_dir = r"C:\Users\Lenovo\Desktop\MATH 4890"

os.makedirs(output_dir, exist_ok=True)

# ==========================
# è¯»å– & é¢„å¤„ç†ï¼ˆå’ŒåŸè„šæœ¬ç›¸åŒï¼‰
# ==========================

df = pd.read_excel(file_path)

# å…¨éƒ¨è½¬æˆæ•°å€¼ï¼Œéæ•°å€¼è½¬ NaN
df = df.apply(pd.to_numeric, errors="coerce")

# æ•°å€¼åˆ—ç”¨å‡å€¼å¡«è¡¥ï¼Œå†æŠŠæ®‹ä½™ NaN å¡« 0
df = df.fillna(df.select_dtypes(include=[np.number]).mean())
df = df.fillna(0)


# ==========================
# æ ¸å¿ƒå‡½æ•°ï¼šç»™å®š targetï¼Œè¾“å‡ºä¸¤ä¸ªæ¨¡å‹çš„å®Œæ•´æ’å
# ==========================

def get_rankings_for_target(df, target, top_k=TOP_K):
    """
    è¿”å›ä¸¤ä¸ª DataFrame:
    enet_rank_df, xgb_rank_df
    æ¯ä¸ªéƒ½åŒ…å«: Rank, Feature, Importance, Importance_norm
    """

    # é¿å…ä¿¡æ¯æ³„éœ²ï¼šæ’é™¤å…¶ä»– target åˆ—
    all_targets = [
        "p_promis_anx_bline",
        "p_promis_dep_bline",
        "a_promis_anx_bline",
        "a_promis_dep_bline",
    ]
    exclude_vars = [t for t in all_targets if t != target]

    X = df.drop(columns=[target] + exclude_vars, errors="ignore")
    y = df[target]

    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

    # ---------- ElasticNet ----------
    enet = ElasticNetCV(
        alphas=np.logspace(-4, 2, 100),
        l1_ratio=np.linspace(0.1, 1.0, 10),
        cv=5,
        random_state=42,
    ).fit(X_scaled, y)

    en_importance = pd.Series(np.abs(enet.coef_), index=X.columns)
    en_ranked = en_importance.sort_values(ascending=False).head(top_k)

    enet_rank_df = (
        en_ranked.reset_index()
        .rename(columns={"index": "Feature", 0: "Importance"})
    )
    enet_rank_df["Rank"] = np.arange(1, len(enet_rank_df) + 1)
    # å½’ä¸€åŒ–æˆç™¾åˆ†æ¯”ï¼ˆç›¸å¯¹æœ€å¤§å€¼ï¼‰
    enet_rank_df["Importance_norm"] = (
        enet_rank_df["Importance"] / enet_rank_df["Importance"].max() * 100
    )

    # ---------- XGBoost ----------
    xgb = XGBRegressor(
        n_estimators=500,
        learning_rate=0.05,
        max_depth=4,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
    ).fit(X_scaled, y)

    xgb_importance = pd.Series(xgb.feature_importances_, index=X.columns)
    xgb_ranked = xgb_importance.sort_values(ascending=False).head(top_k)

    xgb_rank_df = (
        xgb_ranked.reset_index()
        .rename(columns={"index": "Feature", 0: "Importance"})
    )
    xgb_rank_df["Rank"] = np.arange(1, len(xgb_rank_df) + 1)
    xgb_rank_df["Importance_norm"] = (
        xgb_rank_df["Importance"] / xgb_rank_df["Importance"].max() * 100
    )

    return enet_rank_df, xgb_rank_df


# ==========================
# ç”»å•ä¸ªå­å›¾çš„è¾…åŠ©å‡½æ•°
# ==========================

def plot_rank_ax(ax, rank_df, title):
    """
    åœ¨ç»™å®šçš„ ax ä¸Šç”»æ¨ªå‘æ¡å½¢å›¾ï¼š
    y è½´ï¼šRank 1-30
    x è½´ï¼šImportance_norm (%)
    æ¡æ—è¾¹å†™å˜é‡å
    """

    # ä¿è¯ Rank 1 åœ¨æœ€ä¸Šé¢
    rank_df = rank_df.sort_values("Rank")

    y_pos = rank_df["Rank"].values
    x_val = rank_df["Importance_norm"].values
    labels = rank_df["Feature"].values

    ax.barh(y_pos, x_val)
    ax.set_ylim(0.5, max(y_pos) + 0.5)
    ax.invert_yaxis()  # Rank 1 åœ¨æœ€ä¸Šé¢
    ax.set_xlabel("Relative importance (%)")
    ax.set_ylabel("Rank")
    ax.set_title(title, fontsize=11)

    # åœ¨æ¯ä¸ªæ¡å½¢æ—è¾¹å†™å˜é‡å
    for y, x, lbl in zip(y_pos, x_val, labels):
        ax.text(
            x + 1,       # ç¨å¾®åå³ä¸€ç‚¹
            y,
            lbl,
            va="center",
            fontsize=7,
        )


# ==========================
# ä¸»æµç¨‹ï¼šå¯¹ä¸¤ä¸ª target è®¡ç®—æ’åã€ä¿å­˜ Excelã€ç”» 2Ã—2 å›¾
# ==========================

fig, axes = plt.subplots(2, 2, figsize=(12, 10))
axes = axes.flatten()

nice_names_target = {
    "a_promis_anx_bline": "Self-reported anxiety",
    "a_promis_dep_bline": "Self-reported depression",
}
nice_names_model = {
    "ElasticNet": "Elastic Net",
    "XGBoost": "XGBoost",
}

ax_idx = 0

for target in TARGETS_FOR_PLOT:
    print(f"\n===============================")
    print(f"å¤„ç†ç›®æ ‡å˜é‡: {target}")
    print(f"===============================")

    enet_rank_df, xgb_rank_df = get_rankings_for_target(df, target, top_k=TOP_K)

    # ---- ä¿å­˜åˆ° Excel ----
    out_excel = os.path.join(
        output_dir, f"Top30_rank_{target}.xlsx"
    )
    with pd.ExcelWriter(out_excel, engine="openpyxl") as writer:
        enet_rank_df.to_excel(writer, sheet_name="ElasticNet", index=False)
        xgb_rank_df.to_excel(writer, sheet_name="XGBoost", index=False)

    print(f"Top30 æ’åå·²ä¿å­˜åˆ°: {out_excel}")

    # ---- ç”»å›¾ï¼šElasticNet ----
    ax = axes[ax_idx]
    title = f"{nice_names_model['ElasticNet']} - {nice_names_target[target]}"
    plot_rank_ax(ax, enet_rank_df, title)
    ax_idx += 1

    # ---- ç”»å›¾ï¼šXGBoost ----
    ax = axes[ax_idx]
    title = f"{nice_names_model['XGBoost']} - {nice_names_target[target]}"
    plot_rank_ax(ax, xgb_rank_df, title)
    ax_idx += 1

plt.tight_layout()
fig_path = os.path.join(output_dir, "Top30_rank_plots_anx_dep.png")
plt.savefig(fig_path, dpi=300, bbox_inches="tight")
plt.close()

print("\nğŸ‰ æ‰€æœ‰æ’åå›¾å·²ç”Ÿæˆï¼š", fig_path)
print("âœ… Excel æ’åæ–‡ä»¶ä¹Ÿå·²ä¿å­˜å®Œæ¯•ã€‚")

