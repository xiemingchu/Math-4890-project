import pandas as pd
import numpy as np

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import ElasticNetCV
from xgboost import XGBRegressor
from sklearn.svm import SVR
from sklearn.neural_network import MLPRegressor

from sklearn.model_selection import (
    train_test_split,
    KFold,
    LeaveOneOut,
    cross_val_score,
    RandomizedSearchCV,
    cross_val_predict,         # âœ… æ–°å¢ï¼šç”¨æ¥ç”» CV é¢„æµ‹æ•£ç‚¹
)

from sklearn.metrics import r2_score, mean_squared_error
from scipy.stats import uniform, randint
import warnings
warnings.filterwarnings("ignore")

import matplotlib.pyplot as plt   # âœ… ç”»å›¾
import os

# ============================================================
# 0. å›¾åƒè¾“å‡ºè·¯å¾„
# ============================================================

# æŠŠå›¾éƒ½å­˜åˆ°è¿™ä¸ªæ–‡ä»¶å¤¹é‡Œï¼Œä½ å¯ä»¥æŒ‰éœ€è¦æ”¹è·¯å¾„
plot_dir = r"C:\Users\Lenovo\Desktop\MATH 4890\stage2_plots"
os.makedirs(plot_dir, exist_ok=True)

# ä¸€ä¸ªå°å·¥å…·å‡½æ•°ï¼šç”»æ•£ç‚¹å¹¶ä¿å­˜
def plot_scatter(y_true, y_pred, title, filename):
    """
    y_true: ä¸€ç»´çœŸå®å€¼
    y_pred: ä¸€ç»´é¢„æµ‹å€¼
    title: å›¾æ ‡é¢˜
    filename: ä¿å­˜æ–‡ä»¶åï¼ˆä¸å«è·¯å¾„ï¼‰
    """
    plt.figure(figsize=(5, 5))
    plt.scatter(y_true, y_pred, alpha=0.6)
    # ç”» y=x å‚è€ƒçº¿ï¼ŒRÂ² æ­£æ—¶ç‚¹ä¼šæ›´å¤šè´´è¿‘è¿™æ¡çº¿
    min_val = min(y_true.min(), y_pred.min())
    max_val = max(y_true.max(), y_pred.max())
    plt.plot([min_val, max_val], [min_val, max_val], linestyle="--")
    plt.xlabel("True values")
    plt.ylabel("Predicted values")
    plt.title(title)
    plt.tight_layout()
    plt.savefig(os.path.join(plot_dir, filename), dpi=300)
    plt.close()

# ============================================================
# 1. è·¯å¾„ & ç›®æ ‡è®¾ç½®
# ============================================================

# ä¸»æ•°æ®
data_path = r"C:\Users\Lenovo\Desktop\MATH 4890\å˜é‡ç­›é€‰_cleaned.xlsx"

# é˜¶æ®µä¸€å¾—åˆ°çš„â€œé‡åˆå˜é‡â€æ–‡ä»¶ï¼ˆè‡ªè¯„ç„¦è™‘ / è‡ªè¯„æŠ‘éƒï¼‰
feat_path_anx = r"C:\Users\Lenovo\Desktop\MATH 4890\Top30_overlap_a_promis_anx_bline.xlsx"
feat_path_dep = r"C:\Users\Lenovo\Desktop\MATH 4890\Top30_overlap_a_promis_dep_bline.xlsx"

# æ‰€æœ‰ PROMIS ç›®æ ‡å˜é‡ï¼ˆé˜²æ­¢æ³„æ¼ï¼Œè¦ä» X ä¸­å‰”é™¤ï¼‰
PROMIS_TARGETS = [
    "p_promis_anx_bline",
    "p_promis_dep_bline",
    "a_promis_anx_bline",
    "a_promis_dep_bline"
]

# åªåˆ†æè‡ªè¯„çš„ä¸¤ä¸ªç›®æ ‡
SELF_TARGETS = [
    "a_promis_anx_bline",
    "a_promis_dep_bline"
]

FEATURE_FILES = {
    "a_promis_anx_bline": feat_path_anx,
    "a_promis_dep_bline": feat_path_dep
}

# è¾“å‡ºç»“æœ
output_path = r"C:\Users\Lenovo\Desktop\MATH 4890\é˜¶æ®µäºŒ_è‡ªè¯„ç„¦è™‘æŠ‘éƒ_æ¨¡å‹ç»“æœ.xlsx"

# ============================================================
# 2. è¯»å…¥ä¸»æ•°æ®å¹¶é¢„å¤„ç†
# ============================================================

df = pd.read_excel(data_path)

# å°½é‡è½¬æˆæ•°å€¼
df = df.apply(pd.to_numeric, errors="coerce")

# æ•°å€¼åˆ—æŒ‰åˆ—å‡å€¼å¡«è¡¥
df = df.fillna(df.select_dtypes(include=[np.number]).mean())
# è‹¥ä»æœ‰ NaNï¼Œå¡« 0
df = df.fillna(0)

print("æ•°æ®ç»´åº¦ï¼š", df.shape)

# ============================================================
# 3. å·¥å…·å‡½æ•°ï¼šè¯„ä¼° + ç”»å›¾ï¼ˆTrain/Test + 5-fold CV + LOOCV-RMSEï¼‰
# ============================================================

def evaluate_and_plot(model, model_name, target_name,
                      X_train, X_test, y_train, y_test):
    """
    æ‹Ÿåˆæ¨¡å‹ã€è®¡ç®—å„ç§æŒ‡æ ‡ï¼Œå¹¶ç”»ä¸‰å¼ å›¾:
    1ï¼‰Train: y_true vs y_pred_train
    2ï¼‰Test : y_true vs y_pred_test
    3ï¼‰CV   : y_true (train) vs y_pred_cv (5-fold cross_val_predict)
    """

    # ------------ æ‹Ÿåˆ ------------
    model.fit(X_train, y_train)

    # ------------ Train/Test é¢„æµ‹ ------------
    y_pred_train = model.predict(X_train)
    y_pred_test = model.predict(X_test)

    # Train / Test æŒ‡æ ‡
    r2_train = r2_score(y_train, y_pred_train)
    r2_test = r2_score(y_test, y_pred_test)
    rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))
    rmse_test = np.sqrt(mean_squared_error(y_test, y_pred_test))

    # ------------ 5-fold CV æŒ‡æ ‡ï¼ˆå’Œä¹‹å‰ä¸€æ ·ï¼‰------------
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    r2_cv = cross_val_score(model, X_train, y_train, cv=kf, scoring="r2").mean()
    rmse_cv = np.sqrt(
        -cross_val_score(
            model, X_train, y_train,
            cv=kf, scoring="neg_mean_squared_error"
        ).mean()
    )

    # ğŸ‘‰ ä¸ºäº†ç”»â€œCV æ•£ç‚¹å›¾â€ï¼Œæˆ‘ä»¬ç”¨ cross_val_predict å¾—åˆ°
    #    æ¯ä¸ªè®­ç»ƒæ ·æœ¬åœ¨å®ƒçš„éªŒè¯æŠ˜ä¸Šçš„é¢„æµ‹å€¼
    y_pred_cv = cross_val_predict(model, X_train, y_train, cv=kf)
    # è¿™ç»„ (y_train, y_pred_cv) å°±å¯¹åº” R2_CV çš„æ•ˆæœ
    plot_scatter(
        y_train.values,
        y_pred_cv,
        title=f"{target_name} - {model_name} (5-fold CV)",
        filename=f"{target_name}_{model_name}_CV_scatter.png"
    )

    # ------------ LOOCV RMSE ------------
    loo = LeaveOneOut()
    rmse_loo = np.sqrt(
        -cross_val_score(
            model, X_train, y_train,
            cv=loo, scoring="neg_mean_squared_error"
        ).mean()
    )

    # ------------ Train/Test æ•£ç‚¹å›¾ ------------
    # RÂ² ä¸ºæ­£æ—¶ï¼šç‚¹ä¼šé›†ä¸­åœ¨å¯¹è§’çº¿é™„è¿‘ï¼›
    # RÂ² ä¸ºè´Ÿæ—¶ï¼šç‚¹ä¼šæ›´åƒä¸€å›¢äº‘ï¼Œæ–œç‡æ¥è¿‘ 0ã€‚
    plot_scatter(
        y_train.values,
        y_pred_train,
        title=f"{target_name} - {model_name} (Train)",
        filename=f"{target_name}_{model_name}_Train_scatter.png"
    )

    plot_scatter(
        y_test.values,
        y_pred_test,
        title=f"{target_name} - {model_name} (Test)",
        filename=f"{target_name}_{model_name}_Test_scatter.png"
    )

    return r2_train, r2_test, rmse_train, rmse_test, r2_cv, rmse_cv, rmse_loo

# ============================================================
# 4. ä¸»å¾ªç¯ï¼šåˆ†åˆ«å¯¹ è‡ªè¯„ç„¦è™‘ / è‡ªè¯„æŠ‘éƒ å»ºæ¨¡
# ============================================================

results = []

for target in SELF_TARGETS:
    print("\n====================================================")
    print(f"ğŸ¯ å¼€å§‹å»ºæ¨¡ï¼š{target}")
    print("====================================================")

    # ---------- 4.1 è¯»å–è¯¥ target çš„â€œé‡åˆå˜é‡åˆ—è¡¨â€ ----------
    feat_file = FEATURE_FILES[target]
    feat_df = pd.read_excel(feat_file)

    # å‡è®¾æ–‡ä»¶ç¬¬ä¸€åˆ—å°±æ˜¯å˜é‡å
    feat_list = (
        feat_df.iloc[:, 0]
        .dropna()
        .astype(str)
        .tolist()
    )

    print("ğŸ“Œ ä» Excel è¯»åˆ°çš„é‡åˆå˜é‡ä¸ªæ•°ï¼š", len(feat_list))

    # ---------- 4.2 æ„é€  X, y ----------
    # ä»è‡ªå˜é‡ä¸­å‰”é™¤æ‰€æœ‰ PROMIS ç›®æ ‡å˜é‡
    available_cols = [c for c in df.columns if c not in PROMIS_TARGETS]

    # å®é™…å¯ç”¨çš„ç‰¹å¾ = feat_list âˆ© available_cols
    final_feats = [f for f in feat_list if f in available_cols]

    print("âœ… å®é™…å¯ç”¨ç‰¹å¾ä¸ªæ•°ï¼š", len(final_feats))
    print("âœ… ç”¨è¿™äº›ç‰¹å¾å»ºæ¨¡ï¼š", final_feats)

    X = df[final_feats]
    y = df[target]

    # æ ‡å‡†åŒ–
    scaler = StandardScaler()
    X_scaled = pd.DataFrame(
        scaler.fit_transform(X),
        columns=X.columns
    )

    # Train/Test åˆ’åˆ†
    X_train, X_test, y_train, y_test = train_test_split(
        X_scaled, y, test_size=0.2, random_state=42
    )

    # --------------------------------------------------------
    # æ¨¡å‹ 1ï¼šElasticNetï¼ˆå¸¦ CV è°ƒå‚ï¼‰
    # --------------------------------------------------------
    print("\nğŸ”§ æ¨¡å‹ 1ï¼šElasticNet")

    enet = ElasticNetCV(
        alphas=np.logspace(-4, 2, 100),
        l1_ratio=np.linspace(0.1, 1.0, 10),
        cv=5,
        random_state=42
    )

    try:
        scores = evaluate_and_plot(enet, "ElasticNet", target,
                                   X_train, X_test, y_train, y_test)
        results.append([target, "ElasticNet", *scores])
    except Exception as e:
        print("ElasticNet å‡ºé”™ï¼š", e)

    # --------------------------------------------------------
    # æ¨¡å‹ 2ï¼šXGBoostï¼ˆRandomizedSearchCV è°ƒå‚ï¼‰
    # --------------------------------------------------------
    print("\nğŸ”§ æ¨¡å‹ 2ï¼šXGBoostï¼ˆRandomizedSearchCV è°ƒå‚ï¼‰")

    xgb_base = XGBRegressor(
        random_state=42,
        tree_method="hist"
    )

    param_dist_xgb = {
        "n_estimators": randint(200, 800),
        "max_depth": randint(2, 8),
        "learning_rate": uniform(0.01, 0.2),
        "subsample": uniform(0.6, 0.4),
        "colsample_bytree": uniform(0.6, 0.4)
    }

    xgb_search = RandomizedSearchCV(
        xgb_base,
        param_distributions=param_dist_xgb,
        n_iter=30,
        scoring="r2",
        cv=3,
        random_state=42,
        n_jobs=-1
    )

    try:
        xgb_search.fit(X_train, y_train)
        best_xgb = xgb_search.best_estimator_
        print("âœ… XGBoost æœ€ä¼˜å‚æ•°ï¼š", xgb_search.best_params_)

        scores = evaluate_and_plot(best_xgb, "XGBoost", target,
                                   X_train, X_test, y_train, y_test)
        results.append([target, "XGBoost", *scores])
    except Exception as e:
        print("XGBoost å‡ºé”™ï¼š", e)

    # --------------------------------------------------------
    # æ¨¡å‹ 3ï¼šSVRï¼ˆRandomizedSearchCV è°ƒå‚ï¼‰
    # --------------------------------------------------------
    print("\nğŸ”§ æ¨¡å‹ 3ï¼šSVR")

    svr_base = SVR()

    param_dist_svr = {
        "C": uniform(0.1, 10),
        "gamma": uniform(0.001, 0.1),
        "epsilon": uniform(0.01, 0.1)
    }

    svr_search = RandomizedSearchCV(
        svr_base,
        param_distributions=param_dist_svr,
        n_iter=30,
        scoring="r2",
        cv=3,
        random_state=42,
        n_jobs=-1
    )

    try:
        svr_search.fit(X_train, y_train)
        best_svr = svr_search.best_estimator_
        print("âœ… SVR æœ€ä¼˜å‚æ•°ï¼š", svr_search.best_params_)

        scores = evaluate_and_plot(best_svr, "SVR", target,
                                   X_train, X_test, y_train, y_test)
        results.append([target, "SVR", *scores])
    except Exception as e:
        print("SVR å‡ºé”™ï¼š", e)

    # --------------------------------------------------------
    # æ¨¡å‹ 4ï¼šNeuralNetï¼ˆMLPï¼Œæ”¶ç¼©ç½‘ç»œ + ç¨³å®šè°ƒå‚ï¼‰
    # --------------------------------------------------------
    print("\nğŸ”§ æ¨¡å‹ 4ï¼šNeuralNet (MLP)")

    # è¾ƒå°ç½‘ç»œ + æ›´å¼ºæ­£åˆ™ + æå‰åœæ­¢
    mlp_base = MLPRegressor(
        hidden_layer_sizes=(32,),   # å°ä¸€äº›çš„ç½‘ç»œï¼Œé™ä½è¿‡æ‹Ÿåˆé£é™©
        activation="relu",
        solver="adam",
        learning_rate_init=0.001,
        alpha=0.001,                # åŸºç¡€ L2 æ­£åˆ™
        max_iter=3000,
        early_stopping=True,
        n_iter_no_change=30,
        validation_fraction=0.2,
        random_state=42
    )

    # è°ƒå‚èŒƒå›´ï¼šåä¿å®ˆï¼Œä¼˜å…ˆç¨³å®šæ€§
    param_dist_mlp = {
        "hidden_layer_sizes": [(16,), (32,), (48,), (32, 16)],
        "alpha": uniform(1e-4, 5e-3),            # L2 æ­£åˆ™ç•¥å¼º
        "learning_rate_init": uniform(5e-4, 5e-3)
    }

    # scoring ç”¨ neg_mean_squared_errorï¼Œæ›´å…³æ³¨æ•´ä½“è¯¯å·®è€Œä¸æ˜¯ç›²ç›®æ‹‰é«˜ RÂ²
    mlp_search = RandomizedSearchCV(
        mlp_base,
        param_distributions=param_dist_mlp,
        n_iter=30,
        scoring="neg_mean_squared_error",
        cv=5,
        random_state=42,
        n_jobs=-1
    )

    try:
        mlp_search.fit(X_train, y_train)
        best_mlp = mlp_search.best_estimator_
        print("âœ… NeuralNet æœ€ä¼˜å‚æ•°ï¼š", mlp_search.best_params_)

        scores = evaluate_and_plot(best_mlp, "NeuralNet", target,
                                   X_train, X_test, y_train, y_test)
        results.append([target, "NeuralNet", *scores])
    except Exception as e:
        print("NeuralNet å‡ºé”™ï¼š", e)

# ============================================================
# 5. æ±‡æ€» & å¯¼å‡ºç»“æœ
# ============================================================

df_results = pd.DataFrame(
    results,
    columns=[
        "Target", "Model",
        "R2_Train", "R2_Test",
        "RMSE_Train", "RMSE_Test",
        "R2_CV", "RMSE_CV",
        "RMSE_LOOCV"
    ]
)

df_results.to_excel(output_path, index=False)

print("\n====================================================")
print("ğŸ‰ é˜¶æ®µäºŒï¼ˆè‡ªè¯„ç„¦è™‘ + è‡ªè¯„æŠ‘éƒï¼‰å»ºæ¨¡å®Œæˆï¼")
print("ğŸ“ ç»“æœå·²ä¿å­˜åˆ°ï¼š", output_path)
print("ğŸ“Š æ•£ç‚¹å›¾ä¿å­˜åœ¨ï¼š", plot_dir)
print("====================================================")
